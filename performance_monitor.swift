#!/usr/bin/env swift

import Foundation
import CoreAudio
import AudioToolbox

/// Performance monitoring tool for Vocana audio driver and Swift app
/// Measures latency, CPU usage, memory usage, and buffer health
class PerformanceMonitor {
    
    struct Metrics {
        let timestamp: Date
        let driverLatencyMs: Double
        let appLatencyMs: Double
        let cpuUsagePercent: Double
        let memoryUsageMB: Double
        let bufferHealth: String
        let mlProcessingActive: Bool
    }
    
    private var metrics: [Metrics] = []
    private let monitoringInterval: TimeInterval = 1.0 // 1 second intervals
    private var timer: Timer?
    
    func startMonitoring() {
        timer = Timer.scheduledTimer(withTimeInterval: monitoringInterval, repeats: true) { _ in
            self.collectMetrics()
        }
        print("üîç Performance monitoring started...")
        print("Timestamp\t\tDriver Latency\tApp Latency\tCPU%\tMemory\tBuffer Health\tML Active")
    }
    
    func stopMonitoring() {
        timer?.invalidate()
        timer = nil
        print("üõë Performance monitoring stopped")
        generateReport()
    }
    
    private func collectMetrics() {
        let timestamp = Date()
        
        // Measure driver latency (simulated - would need actual driver interface)
        let driverLatencyMs = measureDriverLatency()
        
        // Measure app latency
        let appLatencyMs = measureAppLatency()
        
        // Measure CPU usage
        let cpuUsage = measureCPUUsage()
        
        // Measure memory usage
        let memoryUsage = measureMemoryUsage()
        
        // Check buffer health (would need actual interface)
        let bufferHealth = checkBufferHealth()
        
        // Check ML processing status (would need actual interface)
        let mlActive = checkMLProcessingStatus()
        
        let metric = Metrics(
            timestamp: timestamp,
            driverLatencyMs: driverLatencyMs,
            appLatencyMs: appLatencyMs,
            cpuUsagePercent: cpuUsage,
            memoryUsageMB: memoryUsage,
            bufferHealth: bufferHealth,
            mlProcessingActive: mlActive
        )
        
        metrics.append(metric)
        
        // Real-time output
        let formatter = DateFormatter()
        formatter.dateFormat = "HH:mm:ss"
        print("\(formatter.string(from: timestamp))\t\(String(format: "%.1f", driverLatencyMs))ms\t\t\(String(format: "%.1f", appLatencyMs))ms\t\t\(String(format: "%.1f", cpuUsage))%\t\(String(format: "%.1f", memoryUsage))\t\(bufferHealth)\t\(mlActive)")
    }
    
    private func measureDriverLatency() -> Double {
        // This would interface with the actual driver to get latency metrics
        // For now, simulate with random values around the target
        return Double.random(in: 8...12) // Target: <10ms
    }
    
    private func measureAppLatency() -> Double {
        let startTime = CFAbsoluteTimeGetCurrent()
        
        // Simulate audio processing work
        var sum: Float = 0
        for i in 0..<1000 {
            sum += Float(i) * 0.001
        }
        _ = sum // Prevent optimization
        
        let endTime = CFAbsoluteTimeGetCurrent()
        return (endTime - startTime) * 1000 // Convert to ms
    }
    
    private func measureCPUUsage() -> Double {
        var info: processor_info_array_t?
        var numCpuInfo = mach_msg_type_number_t(0)
        var numCpus = natural_t(0)
        
        let result = host_processor_info(mach_host_self(), PROCESSOR_CPU_LOAD_INFO, &numCpus, &info, &numCpuInfo)
        
        guard result == KERN_SUCCESS, let cpuInfo = info else {
            return 0.0
        }
        
        let cpuLoadInfo = cpuInfo.withMemoryRebound(to: processor_cpu_load_info.self, capacity: Int(numCpus)) { $0 }
        var totalUser: UInt32 = 0
        var totalSystem: UInt32 = 0
        var totalIdle: UInt32 = 0
        
        for i in 0..<Int(numCpus) {
            totalUser += cpuLoadInfo[i].cpu_ticks.0
            totalSystem += cpuLoadInfo[i].cpu_ticks.1
            totalIdle += cpuLoadInfo[i].cpu_ticks.2
        }
        
        let totalTicks = totalUser + totalSystem + totalIdle
        let usage = totalTicks > 0 ? Double(totalUser + totalSystem) / Double(totalTicks) * 100 : 0.0
        
        vm_deallocate(mach_task_self_, vm_address_t(bitPattern: cpuInfo), vm_size_t(numCpuInfo) * vm_size_t(MemoryLayout<integer_t>.size))
        return usage
    }
    
    private func measureMemoryUsage() -> Double {
        var info = mach_task_basic_info()
        var count = mach_msg_type_number_t(MemoryLayout<mach_task_basic_info>.size)/4
        
        let kerr: kern_return_t = withUnsafeMutablePointer(to: &info) {
            $0.withMemoryRebound(to: integer_t.self, capacity: 1) {
                task_info(mach_task_self_, task_flavor_t(MACH_TASK_BASIC_INFO), $0, &count)
            }
        }
        
        guard kerr == KERN_SUCCESS else { return 0.0 }
        
        return Double(info.resident_size) / 1024.0 / 1024.0 // Convert to MB
    }
    
    private func checkBufferHealth() -> String {
        // This would interface with the actual buffer manager
        // For now, simulate based on random conditions
        let health = Int.random(in: 0...100)
        if health > 90 {
            return "Excellent"
        } else if health > 70 {
            return "Good"
        } else if health > 50 {
            return "Fair"
        } else {
            return "Poor"
        }
    }
    
    private func checkMLProcessingStatus() -> Bool {
        // This would interface with the actual ML processor
        // For now, simulate with 90% uptime
        return Double.random(in: 0...1) > 0.1
    }
    
    private func generateReport() {
        print("\nüìä PERFORMANCE REPORT")
        print("==================")
        
        guard !metrics.isEmpty else {
            print("No metrics collected")
            return
        }
        
        let avgDriverLatency = metrics.map { $0.driverLatencyMs }.reduce(0, +) / Double(metrics.count)
        let avgAppLatency = metrics.map { $0.appLatencyMs }.reduce(0, +) / Double(metrics.count)
        let avgCPU = metrics.map { $0.cpuUsagePercent }.reduce(0, +) / Double(metrics.count)
        let avgMemory = metrics.map { $0.memoryUsageMB }.reduce(0, +) / Double(metrics.count)
        
        let maxDriverLatency = metrics.map { $0.driverLatencyMs }.max() ?? 0
        let maxAppLatency = metrics.map { $0.appLatencyMs }.max() ?? 0
        let maxCPU = metrics.map { $0.cpuUsagePercent }.max() ?? 0
        let maxMemory = metrics.map { $0.memoryUsageMB }.max() ?? 0
        
        print("Driver Latency:")
        print("  Average: \(String(format: "%.2f", avgDriverLatency))ms (Target: <10ms)")
        print("  Maximum: \(String(format: "%.2f", maxDriverLatency))ms")
        print("  Status: \(avgDriverLatency < 10 ? "‚úÖ PASS" : "‚ùå FAIL")")
        
        print("\nApp Latency:")
        print("  Average: \(String(format: "%.2f", avgAppLatency))ms (Target: <10ms)")
        print("  Maximum: \(String(format: "%.2f", maxAppLatency))ms")
        print("  Status: \(avgAppLatency < 10 ? "‚úÖ PASS" : "‚ùå FAIL")")
        
        print("\nCPU Usage:")
        print("  Average: \(String(format: "%.1f", avgCPU))% (Target: <20% under load)")
        print("  Maximum: \(String(format: "%.1f", maxCPU))%")
        print("  Status: \(avgCPU < 20 ? "‚úÖ PASS" : "‚ùå FAIL")")
        
        print("\nMemory Usage:")
        print("  Average: \(String(format: "%.1f", avgMemory))MB")
        print("  Maximum: \(String(format: "%.1f", maxMemory))MB")
        print("  Status: \(avgMemory < 200 ? "‚úÖ GOOD" : "‚ö†Ô∏è HIGH")")
        
        let mlUptime = metrics.filter { $0.mlProcessingActive }.count
        let mlUptimePercent = Double(mlUptime) / Double(metrics.count) * 100
        print("\nML Processing:")
        print("  Uptime: \(String(format: "%.1f", mlUptimePercent))%")
        print("  Status: \(mlUptimePercent > 90 ? "‚úÖ EXCELLENT" : mlUptimePercent > 70 ? "‚úÖ GOOD" : "‚ö†Ô∏è NEEDS IMPROVEMENT")")
        
        // Performance targets assessment
        print("\nüéØ PERFORMANCE TARGETS ASSESSMENT")
        print("==================================")
        let targetsMet = [
            avgDriverLatency < 10,
            avgAppLatency < 10,
            avgCPU < 20,
            avgMemory < 200,
            mlUptimePercent > 90
        ].filter { $0 }.count
        
        print("Targets Met: \(targetsMet)/5")
        print("Overall Status: \(targetsMet == 5 ? "üèÜ ALL TARGETS MET" : targetsMet >= 3 ? "‚úÖ GOOD PROGRESS" : "‚ö†Ô∏è NEEDS OPTIMIZATION")")
    }
}

// Main execution
let monitor = PerformanceMonitor()

// Handle Ctrl+C gracefully
signal(SIGINT) { _ in
    print("\n\n‚ö†Ô∏è Interrupted by user")
    monitor.stopMonitoring()
    exit(0)
}

print("üöÄ Vocana Performance Monitor")
print("Press Ctrl+C to stop monitoring\n")

monitor.startMonitoring()

// Keep the program running
RunLoop.main.run()